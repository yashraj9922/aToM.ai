##TRY1
# import streamlit as st
# import pandas as pd
# from lazypredict.Supervised import LazyRegressor
# from sklearn.model_selection import train_test_split
# from sklearn.ensemble import RandomForestRegressor
# from sklearn.metrics import mean_squared_error, r2_score
# from sklearn.datasets import load_diabetes, load_boston
# import matplotlib.pyplot as plt
# import seaborn as sns
# import base64
# import io
# #---------------------------------#
# # Page layout
# ## Page expands to full width
# st.set_page_config(page_title='The Machine Learning Algorithm Comparison App',
#     layout='wide')
# #---------------------------------#
# # Model building
# def build_model(df):
#     df = df.loc[:100] # FOR TESTING PURPOSE, COMMENT THIS OUT FOR PRODUCTION
#     X = df.iloc[:,:-1] # Using all column except for the last column as X
#     Y = df.iloc[:,-1] # Selecting the last column as Y

#     st.markdown('**1.2. Dataset dimension**')
#     st.write('X')
#     st.info(X.shape)
#     st.write('Y')
#     st.info(Y.shape)

#     st.markdown('**1.3. Variable details**:')
#     st.write('X variable (first 20 are shown)')
#     st.info(list(X.columns[:20]))
#     st.write('Y variable')
#     st.info(Y.name)

#     # Build lazy model
#     X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size = split_size,random_state = seed_number)
#     reg = LazyRegressor(verbose=0,ignore_warnings=False, custom_metric=None)
#     models_train,predictions_train = reg.fit(X_train, X_train, Y_train, Y_train)
#     models_test,predictions_test = reg.fit(X_train, X_test, Y_train, Y_test)

#     st.subheader('2. Table of Model Performance')

#     st.write('Training set')
#     st.write(predictions_train)
#     st.markdown(filedownload(predictions_train,'training.csv'), unsafe_allow_html=True)

#     st.write('Test set')
#     st.write(predictions_test)
#     st.markdown(filedownload(predictions_test,'test.csv'), unsafe_allow_html=True)

#     st.subheader('3. Plot of Model Performance (Test set)')


#     with st.markdown('**R-squared**'):
#         # Tall
#         predictions_test["R-Squared"] = [0 if i < 0 else i for i in predictions_test["R-Squared"] ]
#         plt.figure(figsize=(3, 9))
#         sns.set_theme(style="whitegrid")
#         ax1 = sns.barplot(y=predictions_test.index, x="R-Squared", data=predictions_test)
#         ax1.set(xlim=(0, 1))
#     st.markdown(imagedownload(plt,'plot-r2-tall.pdf'), unsafe_allow_html=True)
#         # Wide
#     plt.figure(figsize=(9, 3))
#     sns.set_theme(style="whitegrid")
#     ax1 = sns.barplot(x=predictions_test.index, y="R-Squared", data=predictions_test)
#     ax1.set(ylim=(0, 1))
#     plt.xticks(rotation=90)
#     st.pyplot(plt)
#     st.markdown(imagedownload(plt,'plot-r2-wide.pdf'), unsafe_allow_html=True)

#     with st.markdown('**RMSE (capped at 50)**'):
#         # Tall
#         predictions_test["RMSE"] = [50 if i > 50 else i for i in predictions_test["RMSE"] ]
#         plt.figure(figsize=(3, 9))
#         sns.set_theme(style="whitegrid")
#         ax2 = sns.barplot(y=predictions_test.index, x="RMSE", data=predictions_test)
#     st.markdown(imagedownload(plt,'plot-rmse-tall.pdf'), unsafe_allow_html=True)
#         # Wide
#     plt.figure(figsize=(9, 3))
#     sns.set_theme(style="whitegrid")
#     ax2 = sns.barplot(x=predictions_test.index, y="RMSE", data=predictions_test)
#     plt.xticks(rotation=90)
#     st.pyplot(plt)
#     st.markdown(imagedownload(plt,'plot-rmse-wide.pdf'), unsafe_allow_html=True)

#     with st.markdown('**Calculation time**'):
#         # Tall
#         predictions_test["Time Taken"] = [0 if i < 0 else i for i in predictions_test["Time Taken"] ]
#         plt.figure(figsize=(3, 9))
#         sns.set_theme(style="whitegrid")
#         ax3 = sns.barplot(y=predictions_test.index, x="Time Taken", data=predictions_test)
#     st.markdown(imagedownload(plt,'plot-calculation-time-tall.pdf'), unsafe_allow_html=True)
#         # Wide
#     plt.figure(figsize=(9, 3))
#     sns.set_theme(style="whitegrid")
#     ax3 = sns.barplot(x=predictions_test.index, y="Time Taken", data=predictions_test)
#     plt.xticks(rotation=90)
#     st.pyplot(plt)
#     st.markdown(imagedownload(plt,'plot-calculation-time-wide.pdf'), unsafe_allow_html=True)

# # Download CSV data
# # https://discuss.streamlit.io/t/how-to-download-file-in-streamlit/1806
# def filedownload(df, filename):
#     csv = df.to_csv(index=False)
#     b64 = base64.b64encode(csv.encode()).decode()  # strings <-> bytes conversions
#     href = f'<a href="data:file/csv;base64,{b64}" download={filename}>Download {filename} File</a>'
#     return href

# def imagedownload(plt, filename):
#     s = io.BytesIO()
#     plt.savefig(s, format='pdf', bbox_inches='tight')
#     plt.close()
#     b64 = base64.b64encode(s.getvalue()).decode()  # strings <-> bytes conversions
#     href = f'<a href="data:image/png;base64,{b64}" download={filename}>Download {filename} File</a>'
#     return href

# #---------------------------------#
# st.write("""
# # The Machine Learning Algorithm Comparison App

# In this implementation, the **lazypredict** library is used for building several machine learning models at once.

# Developed by: [Data Professor](http://youtube.com/dataprofessor)

# """)

# #---------------------------------#
# # Sidebar - Collects user input features into dataframe
# with st.sidebar.header('1. Upload your CSV data'):
#     uploaded_file = st.sidebar.file_uploader("Upload your input CSV file", type=["csv"])
#     st.sidebar.markdown("""
# [Example CSV input file](https://raw.githubusercontent.com/dataprofessor/data/master/delaney_solubility_with_descriptors.csv)
# """)

# # Sidebar - Specify parameter settings
# with st.sidebar.header('2. Set Parameters'):
#     split_size = st.sidebar.slider('Data split ratio (% for Training Set)', 10, 90, 80, 5)
#     seed_number = st.sidebar.slider('Set the random seed number', 1, 100, 42, 1)


# #---------------------------------#
# # Main panel

# # Displays the dataset
# st.subheader('1. Dataset')

# if uploaded_file is not None:
#     df = pd.read_csv(uploaded_file)
#     st.markdown('**1.1. Glimpse of dataset**')
#     st.write(df)
#     build_model(df)
# else:
#     st.info('Awaiting for CSV file to be uploaded.')
#     if st.button('Press to use Example Dataset'):
#         # Diabetes dataset
#         #diabetes = load_diabetes()
#         #X = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)
#         #Y = pd.Series(diabetes.target, name='response')
#         #df = pd.concat( [X,Y], axis=1 )

#         #st.markdown('The Diabetes dataset is used as the example.')
#         #st.write(df.head(5))

#         # Boston housing dataset
#         boston = load_boston()
#         #X = pd.DataFrame(boston.data, columns=boston.feature_names)
#         #Y = pd.Series(boston.target, name='response')
#         X = pd.DataFrame(boston.data, columns=boston.feature_names).loc[:100] # FOR TESTING PURPOSE, COMMENT THIS OUT FOR PRODUCTION
#         Y = pd.Series(boston.target, name='response').loc[:100] # FOR TESTING PURPOSE, COMMENT THIS OUT FOR PRODUCTION
#         df = pd.concat( [X,Y], axis=1 )

#         st.markdown('The Boston housing dataset is used as the example.')
#         st.write(df.head(5))
#         build_model(df)


# # App created by Data Professor http://youtube.com/dataprofessor
# # GitHub repo of this app https://github.com/dataprofessor/ml-auto-app
# # Demo of this app https://share.streamlit.io/dataprofessor/ml-auto-app/main/app.py




#TRY2
# import streamlit as st
# import pandas as pd
# import h2o
# from h2o.automl import H2OAutoML
# from sklearn.datasets import load_boston
# import matplotlib.pyplot as plt
# import seaborn as sns
# import base64
# import io

# #---------------------------------#
# # Page layout
# ## Page expands to full width
# st.set_page_config(page_title='The Machine Learning Algorithm Comparison App',
#     layout='wide')

# # Start H2O cluster
# h2o.init(nthreads=-1)  # Use all available threads

# #---------------------------------#
# # Model building
# def build_model(df):
#     # Convert the Pandas DataFrame to H2OFrame
#     h2o_df = h2o.H2OFrame(df)

#     # Set the target variable and features
#     target = df.columns[-1]
#     features = df.columns[:-1].tolist()

#     st.markdown('**1.2. Dataset dimension**')
#     st.write('Features:', h2o_df.ncol - 1)
#     st.write('Target:', h2o_df.ncol)

#     st.markdown('**1.3. Variable details**:')
#     st.write('X variables (first 20 are shown):', features[:20])
#     st.write('Y variable:', target)

#     # Split the dataset into training and testing sets
#     train, test = h2o_df.split_frame(ratios=[0.8], seed=42)

#     # Train the H2O AutoML model
#     st.subheader('Training the AutoML model...')
#     with st.spinner("Training..."):
#         aml = H2OAutoML(max_runtime_secs=3600, seed=1)
#         aml.train(x=features, y=target, training_frame=train)

#     # Leaderboard
#     leaderboard = aml.leaderboard
#     st.subheader('2. Table of Model Performance')
#     st.write(leaderboard)

#     # Save predictions for test set
#     predictions = aml.predict(test)

#     # Combine predictions with actual values
#     results = test.cbind(predictions)
#     results_df = results.as_data_frame()

#     st.markdown('**Predictions vs Actual**:')
#     st.write(results_df[[target, 'predict']])

#     # Plot R-Squared and RMSE
#     st.subheader('3. Model Performance Visualizations')
    
#     # Extract model performance metrics
#     metrics = leaderboard[['model_id', 'r2', 'rmse']].as_data_frame()
#     metrics['model_id'] = metrics['model_id'].astype(str)

#     # R-Squared plot
#     plt.figure(figsize=(9, 5))
#     sns.barplot(x='r2', y='model_id', data=metrics, palette='viridis')
#     plt.title('R-Squared of Different Models')
#     plt.xlabel('R-Squared')
#     plt.ylabel('Model')
#     st.pyplot(plt)

#     # RMSE plot
#     plt.figure(figsize=(9, 5))
#     sns.barplot(x='rmse', y='model_id', data=metrics, palette='viridis')
#     plt.title('RMSE of Different Models')
#     plt.xlabel('RMSE')
#     plt.ylabel('Model')
#     st.pyplot(plt)

# # Download CSV data
# def filedownload(df, filename):
#     csv = df.to_csv(index=False)
#     b64 = base64.b64encode(csv.encode()).decode()  # strings <-> bytes conversions
#     href = f'<a href="data:file/csv;base64,{b64}" download={filename}>Download {filename} File</a>'
#     return href

# #---------------------------------#
# st.write("""
# # The Machine Learning Algorithm Comparison App

# In this implementation, the **H2O.ai** library is used for building several machine learning models automatically.

# Developed by: [Data Professor](http://youtube.com/dataprofessor)
# """)

# #---------------------------------#
# # Sidebar - Collects user input features into dataframe
# with st.sidebar.header('1. Upload your CSV data'):
#     uploaded_file = st.sidebar.file_uploader("Upload your input CSV file", type=["csv"])
#     st.sidebar.markdown("""
# [Example CSV input file](https://raw.githubusercontent.com/dataprofessor/data/master/delaney_solubility_with_descriptors.csv)
# """)

# # Sidebar - Specify parameter settings
# with st.sidebar.header('2. Set Parameters'):
#     split_size = st.sidebar.slider('Data split ratio (% for Training Set)', 10, 90, 80, 5)
#     seed_number = st.sidebar.slider('Set the random seed number', 1, 100, 42, 1)

# #---------------------------------#
# # Main panel

# # Displays the dataset
# st.subheader('1. Dataset')

# if uploaded_file is not None:
#     df = pd.read_csv(uploaded_file)
#     st.markdown('**1.1. Glimpse of dataset**')
#     st.write(df)
#     build_model(df)
# else:
#     st.info('Awaiting for CSV file to be uploaded.')
#     if st.button('Press to use Example Dataset'):
#         boston = load_boston()
#         X = pd.DataFrame(boston.data, columns=boston.feature_names).loc[:100] # FOR TESTING PURPOSE, COMMENT THIS OUT FOR PRODUCTION
#         Y = pd.Series(boston.target, name='response').loc[:100] # FOR TESTING PURPOSE, COMMENT THIS OUT FOR PRODUCTION
#         df = pd.concat([X, Y], axis=1)

#         st.markdown('The Boston housing dataset is used as the example.')
#         st.write(df.head(5))

#         build_model(df)

# # Shutdown H2O cluster
# h2o.shutdown()


##TRY3
# import streamlit as st
# import pandas as pd
# from lazypredict.Supervised import LazyRegressor
# from sklearn.model_selection import train_test_split
# import h2o
# from h2o.automl import H2OAutoML
# import matplotlib.pyplot as plt
# import seaborn as sns
# import base64
# import io

# # Initialize H2O
# h2o.init(nthreads=-1)  # Use all available threads

# # Download CSV data function
# def filedownload(df, filename):
#     csv = df.to_csv(index=False)
#     b64 = base64.b64encode(csv.encode()).decode()  # strings <-> bytes conversions
#     href = f'<a href="data:file/csv;base64,{b64}" download={filename}>Download {filename} File</a>'
#     return href

# def imagedownload(plt, filename):
#     s = io.BytesIO()
#     plt.savefig(s, format='pdf', bbox_inches='tight')
#     plt.close()
#     b64 = base64.b64encode(s.getvalue()).decode()  # strings <-> bytes conversions
#     href = f'<a href="data:image/png;base64,{b64}" download={filename}>Download {filename} File</a>'
#     return href

# #---------------------------------#
# # Page layout
# st.set_page_config(page_title='Machine Learning Algorithm Comparison App', layout='wide')

# # Model building function
# def build_model(df):
#     df = df.loc[:100]  # FOR TESTING PURPOSE, COMMENT THIS OUT FOR PRODUCTION
#     X = df.iloc[:, :-1]  # Using all columns except for the last column as X
#     Y = df.iloc[:, -1]  # Selecting the last column as Y

#     st.markdown('**1.2. Dataset dimension**')
#     st.write('X')
#     st.info(X.shape)
#     st.write('Y')
#     st.info(Y.shape)

#     # Build lazy model
#     X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=split_size, random_state=seed_number)
#     reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)
#     models_train, predictions_train = reg.fit(X_train, X_train, Y_train, Y_train)
#     models_test, predictions_test = reg.fit(X_train, X_test, Y_train, Y_test)

#     st.subheader('2. Table of Model Performance (LazyPredict)')
#     st.write('Training set')
#     st.write(predictions_train)
#     st.markdown(filedownload(predictions_train, 'training_lazypredict.csv'), unsafe_allow_html=True)

#     st.write('Test set')
#     st.write(predictions_test)
#     st.markdown(filedownload(predictions_test, 'test_lazypredict.csv'), unsafe_allow_html=True)

#     # Plot LazyPredict performance
#     st.subheader('3. Plot of Model Performance (Test set - LazyPredict)')
#     with st.markdown('**R-squared**'):
#         predictions_test["R-Squared"] = [0 if i < 0 else i for i in predictions_test["R-Squared"]]
#         plt.figure(figsize=(3, 9))
#         sns.set_theme(style="whitegrid")
#         ax1 = sns.barplot(y=predictions_test.index, x="R-Squared", data=predictions_test)
#         ax1.set(xlim=(0, 1))
#         st.markdown(imagedownload(plt, 'plot-r2-tall.pdf'), unsafe_allow_html=True)

#         plt.figure(figsize=(9, 3))
#         ax1 = sns.barplot(x=predictions_test.index, y="R-Squared", data=predictions_test)
#         ax1.set(ylim=(0, 1))
#         plt.xticks(rotation=90)
#         st.pyplot(plt)
#         st.markdown(imagedownload(plt, 'plot-r2-wide.pdf'), unsafe_allow_html=True)

#     with st.markdown('**RMSE (capped at 50)**'):
#         predictions_test["RMSE"] = [50 if i > 50 else i for i in predictions_test["RMSE"]]
#         plt.figure(figsize=(3, 9))
#         sns.set_theme(style="whitegrid")
#         ax2 = sns.barplot(y=predictions_test.index, x="RMSE", data=predictions_test)
#         st.markdown(imagedownload(plt, 'plot-rmse-tall.pdf'), unsafe_allow_html=True)

#         plt.figure(figsize=(9, 3))
#         ax2 = sns.barplot(x=predictions_test.index, y="RMSE", data=predictions_test)
#         plt.xticks(rotation=90)
#         st.pyplot(plt)
#         st.markdown(imagedownload(plt, 'plot-rmse-wide.pdf'), unsafe_allow_html=True)

#     with st.markdown('**Calculation time**'):
#         predictions_test["Time Taken"] = [0 if i < 0 else i for i in predictions_test["Time Taken"]]
#         plt.figure(figsize=(3, 9))
#         sns.set_theme(style="whitegrid")
#         ax3 = sns.barplot(y=predictions_test.index, x="Time Taken", data=predictions_test)
#         st.markdown(imagedownload(plt, 'plot-calculation-time-tall.pdf'), unsafe_allow_html=True)

#         plt.figure(figsize=(9, 3))
#         ax3 = sns.barplot(x=predictions_test.index, y="Time Taken", data=predictions_test)
#         plt.xticks(rotation=90)
#         st.pyplot(plt)
#         st.markdown(imagedownload(plt, 'plot-calculation-time-wide.pdf'), unsafe_allow_html=True)

#     # H2O AutoML
#     st.subheader('4. H2O AutoML Model Training')
#     h2o_df = h2o.H2OFrame(df)
#     aml = H2OAutoML(max_models=10, seed=seed_number, max_runtime_secs=300)
#     aml.train(x=list(h2o_df.columns[:-1]), y=h2o_df.columns[-1], training_frame=h2o_df)
    
#     # Get leaderboard
#     leaderboard = aml.leaderboard.as_data_frame()
#     st.write(leaderboard)

#     # Plot H2O model performance
#     st.subheader('5. H2O AutoML Leaderboard Plot')
#     plt.figure(figsize=(10, 6))
#     sns.barplot(y='model_id', x='mse', data=leaderboard)
#     plt.title('H2O AutoML Leaderboard')
#     st.pyplot(plt)

# #---------------------------------#
# st.write("""
# # The Machine Learning Algorithm Comparison App

# In this implementation, the **LazyPredict** library is used for building several machine learning models at once, and **H2O AutoML** for advanced model training.

# Developed by: [Your Name or Organization]
# """)

# #---------------------------------#
# # Sidebar - Collects user input features into dataframe
# with st.sidebar.header('1. Upload your CSV data'):
#     uploaded_file = st.sidebar.file_uploader("Upload your input CSV file", type=["csv"])
#     st.sidebar.markdown("""[Example CSV input file](https://raw.githubusercontent.com/dataprofessor/data/master/delaney_solubility_with_descriptors.csv)""")

# # Sidebar - Specify parameter settings
# with st.sidebar.header('2. Set Parameters'):
#     split_size = st.sidebar.slider('Data split ratio (% for Training Set)', 10, 90, 80, 5)
#     seed_number = st.sidebar.slider('Set the random seed number', 1, 100, 42, 1)

# #---------------------------------#
# # Main panel
# st.subheader('1. Dataset')

# if uploaded_file is not None:
#     df = pd.read_csv(uploaded_file)
#     st.markdown('**1.1. Glimpse of dataset**')
#     st.write(df)
#     build_model(df)
# else:
#     st.info('Awaiting for CSV file to be uploaded.')
#     if st.button('Press to use Example Dataset'):
#         # Load example dataset (e.g., Boston housing dataset)
#         from sklearn.datasets import fetch_california_housing
#         california = fetch_california_housing()
#         X = pd.DataFrame(california.data, columns=california.feature_names).loc[:100]  # FOR TESTING PURPOSE, COMMENT THIS OUT FOR PRODUCTION
#         Y = pd.Series(california.target, name='response').loc[:100]  # FOR TESTING PURPOSE, COMMENT THIS OUT FOR PRODUCTION
#         df = pd.concat([X, Y], axis=1)
#         df = pd.concat([X, Y], axis=1)

#         st.markdown('The Boston housing dataset is used as the example.')
#         st.write(df.head(5))
#         build_model(df)


##TRY4
# App created by Data Professor http://youtube.com/dataprofessor
# GitHub repo of this app https://github.com/dataprofessor/ml-auto-app
# Demo of this app https://share.streamlit.io/dataprofessor/ml-auto-app/main/app.py
# App created by Data Professor http://youtube.com/dataprofessor
# GitHub repo of this app https://github.com/dataprofessor/ml-auto-app
# Demo of this app https://share.streamlit.io/dataprofessor/ml-auto-app/main/app.py

import streamlit as st
import pandas as pd
from lazypredict.Supervised import LazyRegressor
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_boston
import matplotlib.pyplot as plt
import seaborn as sns
import base64
import io
import joblib
import os

#---------------------------------#
# Page layout
## Page expands to full width
st.set_page_config(page_title='The Machine Learning Algorithm Comparison App',
    layout='wide')

#---------------------------------#
# Model building
def build_model(df):
    df = df.loc[:100]  # FOR TESTING PURPOSE, COMMENT THIS OUT FOR PRODUCTION
    X = df.iloc[:, :-1]  # Using all column except for the last column as X
    Y = df.iloc[:, -1]  # Selecting the last column as Y

    st.markdown('**1.2. Dataset dimension**')
    st.write('X')
    st.info(X.shape)
    st.write('Y')
    st.info(Y.shape)

    st.markdown('**1.3. Variable details**:')
    st.write('X variable (first 20 are shown)')
    st.info(list(X.columns[:20]))
    st.write('Y variable')
    st.info(Y.name)

    # Build lazy model
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=split_size, random_state=seed_number)
    reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)
    models_train, predictions_train = reg.fit(X_train, X_train, Y_train, Y_train)
    models_test, predictions_test = reg.fit(X_train, X_test, Y_train, Y_test)

    st.subheader('2. Table of Model Performance')
    st.write('Training set')
    st.write(predictions_train)
    st.markdown(filedownload(predictions_train, 'training.csv'), unsafe_allow_html=True)

    st.write('Test set')
    st.write(predictions_test)
    st.markdown(filedownload(predictions_test, 'test.csv'), unsafe_allow_html=True)

    st.subheader('3. Plot of Model Performance (Test set)')

    with st.markdown('**R-squared**'):
        predictions_test["R-Squared"] = [0 if i < 0 else i for i in predictions_test["R-Squared"]]
        plt.figure(figsize=(3, 9))
        sns.set_theme(style="whitegrid")
        ax1 = sns.barplot(y=predictions_test.index, x="R-Squared", data=predictions_test)
        ax1.set(xlim=(0, 1))
    st.markdown(imagedownload(plt, 'plot-r2-tall.pdf'), unsafe_allow_html=True)

    plt.figure(figsize=(9, 3))
    sns.set_theme(style="whitegrid")
    ax1 = sns.barplot(x=predictions_test.index, y="R-Squared", data=predictions_test)
    ax1.set(ylim=(0, 1))
    plt.xticks(rotation=90)
    st.pyplot(plt)
    st.markdown(imagedownload(plt, 'plot-r2-wide.pdf'), unsafe_allow_html=True)

    # Download best model
    model_filename = 'best_model.pkl'
    joblib.dump(reg, model_filename)  # Save the model
    st.markdown(f"<a href='data:file/pkl;base64,{base64.b64encode(open(model_filename, 'rb').read()).decode()}' download='{model_filename}'>Download Best Model</a>", unsafe_allow_html=True)

# Download CSV data
def filedownload(df, filename):
    csv = df.to_csv(index=False)
    b64 = base64.b64encode(csv.encode()).decode()  # strings <-> bytes conversions
    href = f'<a href="data:file/csv;base64,{b64}" download={filename}>Download {filename} File</a>'
    return href

def imagedownload(plt, filename):
    s = io.BytesIO()
    plt.savefig(s, format='pdf', bbox_inches='tight')
    plt.close()
    b64 = base64.b64encode(s.getvalue()).decode()  # strings <-> bytes conversions
    href = f'<a href="data:image/png;base64,{b64}" download={filename}>Download {filename} File</a>'
    return href

#---------------------------------#
st.write("""
# The Machine Learning Algorithm Comparison App

In this implementation, the **lazypredict** library is used for building several machine learning models at once.

Developed by: [Data Professor](http://youtube.com/dataprofessor)

""")

#---------------------------------#
# Sidebar - Collects user input features into dataframe
with st.sidebar.header('1. Upload your CSV data'):
    uploaded_file = st.sidebar.file_uploader("Upload your input CSV file", type=["csv"])
    st.sidebar.markdown("""
[Example CSV input file](https://raw.githubusercontent.com/dataprofessor/data/master/delaney_solubility_with_descriptors.csv)
""")

# Sidebar - Specify parameter settings
with st.sidebar.header('2. Set Parameters'):
    split_size = st.sidebar.slider('Data split ratio (% for Training Set)', 10, 90, 80, 5)
    seed_number = st.sidebar.slider('Set the random seed number', 1, 100, 42, 1)

#---------------------------------#
# Main panel

# Displays the dataset
st.subheader('1. Dataset')

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    st.markdown('**1.1. Glimpse of dataset**')
    st.write(df)
    build_model(df)
else:
    st.info('Awaiting for CSV file to be uploaded.')
    if st.button('Press to use Example Dataset'):
        # Boston housing dataset
        boston = load_boston()
        X = pd.DataFrame(boston.data, columns=boston.feature_names).loc[:100]  # FOR TESTING PURPOSE, COMMENT THIS OUT FOR PRODUCTION
        Y = pd.Series(boston.target, name='response').loc[:100]  # FOR TESTING PURPOSE, COMMENT THIS OUT FOR PRODUCTION
        df = pd.concat([X, Y], axis=1)

        st.markdown('The Boston housing dataset is used as the example.')
        st.write(df.head(5))

        build_model(df)
